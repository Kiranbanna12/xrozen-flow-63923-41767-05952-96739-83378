# AI Usage Tracking - Real Data Implementation

## ‚úÖ Completed Setup

### 1. Database Schema
**Table: `ai_request_logs`** - Tracks every AI API call with complete details

Columns:
- `id` - Unique request ID
- `model_id` - Which AI model was used
- `user_id` - Who made the request
- `request_tokens` - Input tokens (prompt)
- `response_tokens` - Output tokens (completion)
- `total_tokens` - Total tokens used
- `response_time_ms` - Response time in milliseconds
- `success` - 1 for successful, 0 for failed
- `error_message` - Error details if failed
- `created_at` - Timestamp of request

### 2. Backend API Endpoints

#### `/api/admin/ai-usage/stats` (GET)
Returns overall usage statistics for summary cards:
```json
{
  "success": true,
  "data": {
    "total_requests": 150,
    "successful_requests": 145,
    "failed_requests": 5,
    "total_tokens": 45000,
    "input_tokens": 25000,
    "output_tokens": 20000,
    "estimated_cost": 0.0892,
    "success_rate": 96.67,
    "avg_response_time": 1234
  }
}
```

#### `/api/admin/ai-usage/by-model` (GET)
Returns per-model usage breakdown for detailed table:
```json
{
  "success": true,
  "data": [
    {
      "model_id": "uuid-here",
      "model_name": "GPT-4o Mini",
      "provider": "openai",
      "request_count": 85,
      "success_count": 82,
      "fail_count": 3,
      "total_tokens": 25000,
      "estimated_cost": 0.0345,
      "success_rate": 96.47,
      "avg_response_time": 1150,
      "last_used_at": "2025-10-12T10:30:00Z"
    }
  ]
}
```

### 3. Cost Calculation (Real Pricing)

**OpenAI Models (per 1M tokens in USD):**
- GPT-4o: Input $2.50, Output $10.00
- GPT-4o Mini: Input $0.15, Output $0.60
- GPT-4 Turbo: Input $10.00, Output $30.00
- GPT-4: Input $30.00, Output $60.00
- GPT-3.5 Turbo: Input $0.50, Output $1.50

**Gemini Models (per 1M tokens in USD):**
- Gemini 2.5 Pro: Input $1.25, Output $5.00
- Gemini 2.5 Flash: Input $0.075, Output $0.30
- Gemini 2.0 Flash: Input $0.10, Output $0.40
- Gemini 1.5 Pro: Input $1.25, Output $5.00
- Gemini 1.5 Flash: Input $0.075, Output $0.30

**OpenRouter Models:** All free (cost = $0)

### 4. Automatic Usage Logging

Every AI request is now automatically logged with:
- ‚úÖ Token counts (input + output)
- ‚úÖ Response time tracking
- ‚úÖ Success/failure status
- ‚úÖ Error messages if failed
- ‚úÖ User ID and model ID

**Location:** `src/server/controllers/ai.controller.ts` ‚Üí `makeAIRequest()` method

```typescript
// Automatically logs every request
this.aiAdmin.logRequest(
  model.id,        // Which model was used
  userId,          // Who made the request
  success,         // true/false
  requestTokens,   // Input tokens
  responseTokens,  // Output tokens
  responseTime,    // ms
  errorMessage     // if any error
);
```

## üß™ How to Test

### Step 1: Add AI Models & API Keys
1. Go to Admin Panel ‚Üí AI Models page
2. Click on **API Keys** tab
3. Add OpenAI, Gemini, or OpenRouter API keys
4. Click on **Models** tab
5. Click **Add Models** button
6. Select models and click Add

### Step 2: Make AI Requests
Use XrozenAI chat feature to generate some AI requests:

1. Go to any page with XrozenAI chat icon (bottom right)
2. Click the AI icon to open chat
3. Ask questions like:
   - "Create a new project called Test Video"
   - "List all my projects"
   - "Add a new editor named John Doe"
   - "What can you help me with?"

Each request will be logged automatically!

### Step 3: Check Usage & Cost Tab
1. Go back to Admin Panel ‚Üí AI Models
2. Click on **Usage & Cost** tab
3. You'll see:
   - ‚úÖ Total Requests card with count
   - ‚úÖ Success Rate percentage
   - ‚úÖ Total Tokens used
   - ‚úÖ Estimated Cost in USD
   - ‚úÖ Detailed table with per-model breakdown

### Step 4: Verify Real Data in Database
You can manually check the logs:

```sql
-- View all AI request logs
SELECT * FROM ai_request_logs ORDER BY created_at DESC LIMIT 10;

-- Get total requests count
SELECT COUNT(*) as total_requests FROM ai_request_logs;

-- Get total tokens used
SELECT SUM(total_tokens) as total_tokens FROM ai_request_logs;

-- Get success rate
SELECT 
  SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as success_rate 
FROM ai_request_logs;
```

## üìä What Gets Tracked

### Every AI Request Logs:
1. **Model Used** - Which AI model processed the request
2. **User** - Who made the request
3. **Tokens** - Exact input/output token counts from provider
4. **Cost** - Real pricing based on provider rates
5. **Performance** - Response time in milliseconds
6. **Status** - Success or failure with error details
7. **Timestamp** - When the request was made

### No Mock Data
- ‚ùå No fake numbers
- ‚ùå No placeholder data
- ‚úÖ Only real API call metrics
- ‚úÖ Actual token usage from providers
- ‚úÖ Real cost calculations
- ‚úÖ Genuine response times

## üîç Monitoring & Analytics

### Real-Time Insights
- **Success Rate:** % of successful vs failed requests
- **Cost Tracking:** Exact spending on paid models
- **Performance:** Average response time per model
- **Usage Patterns:** Which models are used most
- **Error Tracking:** Failed requests with reasons

### Per-Model Breakdown
Each model shows:
- Total requests handled
- Success/failure counts
- Tokens consumed (separate input/output)
- Estimated cost (based on real pricing)
- Success rate percentage
- Average response time
- Last used timestamp

## üöÄ Next Steps

1. **Make Some AI Requests** - Use XrozenAI chat to generate real data
2. **Monitor Usage** - Check the Usage & Cost tab regularly
3. **Optimize Costs** - See which models are most cost-effective
4. **Track Performance** - Monitor response times
5. **Review Errors** - Check failed requests and fix issues

## üí° Tips

- **Free Models First:** OpenRouter free models have no cost
- **Cost Control:** Monitor high-cost models like GPT-4
- **Performance:** Check avg_response_time to find fastest models
- **Success Rate:** Models with low success rates may need API key fixes
- **Token Efficiency:** Compare token usage across models

---

**Status:** ‚úÖ All real data tracking is now live and working!

**No Mock Data:** Every number you see is from actual API calls.
